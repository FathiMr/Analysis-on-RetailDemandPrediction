{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3276009",
   "metadata": {},
   "source": [
    "# 1. Import data\n",
    "\n",
    "The primary dataset includes the selling retail data of 44 products for a hundred weeks. There are 8 recorded features in the initial dataset: week, product item, weekly_sales, functionality, featured on the web page, color, and vendor. After some pre-processing steps, we have our dataset ready for interpretation and forecasting. Please visit the  following book to be more familiar with the features and pre-processing steps:\n",
    "\n",
    "https://www.springerprofessional.de/en/demand-prediction-in-retail/19981986.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "298f373a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>sku</th>\n",
       "      <th>weekly_sales</th>\n",
       "      <th>price</th>\n",
       "      <th>price-1</th>\n",
       "      <th>price-2</th>\n",
       "      <th>feat_main_page</th>\n",
       "      <th>trend</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>...</th>\n",
       "      <th>color_white</th>\n",
       "      <th>vendor_2</th>\n",
       "      <th>vendor_3</th>\n",
       "      <th>vendor_4</th>\n",
       "      <th>vendor_5</th>\n",
       "      <th>vendor_6</th>\n",
       "      <th>vendor_7</th>\n",
       "      <th>vendor_8</th>\n",
       "      <th>vendor_9</th>\n",
       "      <th>vendor_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>10.24</td>\n",
       "      <td>9.86</td>\n",
       "      <td>10.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-21</td>\n",
       "      <td>1</td>\n",
       "      <td>127.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>10.24</td>\n",
       "      <td>9.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>1</td>\n",
       "      <td>84.0</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.27</td>\n",
       "      <td>10.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.98</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-12</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>10.40</td>\n",
       "      <td>8.98</td>\n",
       "      <td>8.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>2018-08-27</td>\n",
       "      <td>44</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.99</td>\n",
       "      <td>42.38</td>\n",
       "      <td>43.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>2018-09-03</td>\n",
       "      <td>44</td>\n",
       "      <td>14.0</td>\n",
       "      <td>52.99</td>\n",
       "      <td>53.99</td>\n",
       "      <td>42.38</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>44</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.99</td>\n",
       "      <td>52.99</td>\n",
       "      <td>53.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>2018-09-17</td>\n",
       "      <td>44</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42.99</td>\n",
       "      <td>44.99</td>\n",
       "      <td>52.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>2018-09-24</td>\n",
       "      <td>44</td>\n",
       "      <td>26.0</td>\n",
       "      <td>43.45</td>\n",
       "      <td>42.99</td>\n",
       "      <td>44.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4312 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            week  sku  weekly_sales  price  price-1  price-2  feat_main_page  \\\n",
       "0     2016-11-14    1         110.0  10.24     9.86    10.16               1   \n",
       "1     2016-11-21    1         127.0   8.27    10.24     9.86               1   \n",
       "2     2016-11-28    1          84.0   8.83     8.27    10.24               1   \n",
       "3     2016-12-05    1          87.0   8.98     8.83     8.27               1   \n",
       "4     2016-12-12    1          64.0  10.40     8.98     8.83               1   \n",
       "...          ...  ...           ...    ...      ...      ...             ...   \n",
       "4307  2018-08-27   44          20.0  53.99    42.38    43.99               0   \n",
       "4308  2018-09-03   44          14.0  52.99    53.99    42.38               0   \n",
       "4309  2018-09-10   44          22.0  44.99    52.99    53.99               1   \n",
       "4310  2018-09-17   44          28.0  42.99    44.99    52.99               1   \n",
       "4311  2018-09-24   44          26.0  43.45    42.99    44.99               1   \n",
       "\n",
       "      trend  month_2  month_3  ...  color_white  vendor_2  vendor_3  vendor_4  \\\n",
       "0         0        0        0  ...            0         0         0         0   \n",
       "1         0        0        0  ...            0         0         0         0   \n",
       "2         0        0        0  ...            0         0         0         0   \n",
       "3         0        0        0  ...            0         0         0         0   \n",
       "4         0        0        0  ...            0         0         0         0   \n",
       "...     ...      ...      ...  ...          ...       ...       ...       ...   \n",
       "4307      2        0        0  ...            0         0         0         0   \n",
       "4308      2        0        0  ...            0         0         0         0   \n",
       "4309      2        0        0  ...            0         0         0         0   \n",
       "4310      2        0        0  ...            0         0         0         0   \n",
       "4311      2        0        0  ...            0         0         0         0   \n",
       "\n",
       "      vendor_5  vendor_6  vendor_7  vendor_8  vendor_9  vendor_10  \n",
       "0            0         1         0         0         0          0  \n",
       "1            0         1         0         0         0          0  \n",
       "2            0         1         0         0         0          0  \n",
       "3            0         1         0         0         0          0  \n",
       "4            0         1         0         0         0          0  \n",
       "...        ...       ...       ...       ...       ...        ...  \n",
       "4307         0         1         0         0         0          0  \n",
       "4308         0         1         0         0         0          0  \n",
       "4309         0         1         0         0         0          0  \n",
       "4310         0         1         0         0         0          0  \n",
       "4311         0         1         0         0         0          0  \n",
       "\n",
       "[4312 rows x 48 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sales=pd.read_csv(\"data_processed.csv\")\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f778f4",
   "metadata": {},
   "source": [
    "# 2. Centralized and decentralized approaches\n",
    "\n",
    "There are two general approaches to predict the demand of products. The first is to consider a single predictor for all product items, called centralized method, and the other approach is to consider products separately, called decentralized method. With regard to prediction accuracy, I found that there is no rigid priority to use either centralized or decentralized appraoches. For the prediction, we use the linear regression method. The 'res' dataframe is created to save the prediction accuracy of methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "446e0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "res=pd.DataFrame(index=['R2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb9ea0e",
   "metadata": {},
   "source": [
    "## 2.1. Structuring the dataset\n",
    "\n",
    "Before proceeding to the approaches mentioned above, we need to split our data into train and test datasets for each specific product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d539a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "skuSet = list(sales.sku.unique())\n",
    "skuData = {}\n",
    "colnames = [i for i in sales.columns if i not in [\"week\",\"weekly_sales\",\"sku\"]]\n",
    "for i in skuSet:\n",
    "  df_i = sales[sales.sku == i]\n",
    "  skuData[i] = {'X': df_i[colnames].values,\n",
    "                'y': df_i.weekly_sales.values}\n",
    "    \n",
    "X_dict = {}\n",
    "y_dict = {}\n",
    "\n",
    "y_test = []\n",
    "y_train = []\n",
    "\n",
    "for i in skuSet:\n",
    "  \n",
    "  X_train_i,X_test_i = train_test_split(skuData[i][\"X\"], shuffle=False, train_size=0.7) #split for X\n",
    "  y_train_i,y_test_i = train_test_split(skuData[i][\"y\"], shuffle=False, train_size=0.7) #split for y \n",
    "\n",
    "  X_dict[i] = {'train': X_train_i, 'test': X_test_i} #filling dictionary\n",
    "  y_dict[i] = {'train': y_train_i, 'test': y_test_i}\n",
    "\n",
    "  y_test += list(y_test_i) \n",
    "  y_train += list(y_train_i) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e044e8",
   "metadata": {},
   "source": [
    "## 2.2. Centralized method\n",
    "\n",
    " Once the train and test datasets are created for each product, we combine them to deploy our centralized solution method and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8fef63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centralized method with linear regression R2: 0.114\n",
      "Centralized method with linear regression MSE: 98086.301\n"
     ]
    }
   ],
   "source": [
    "X_cen_train = X_dict[skuSet[0]]['train'] #initialization with item 0\n",
    "X_cen_test = X_dict[skuSet[0]]['test']\n",
    "\n",
    "for i in skuSet[1:]: #Iteration over items\n",
    "    X_cen_train = np.concatenate((X_cen_train, X_dict[i]['train']), axis = 0) #Bringing together the training set\n",
    "    X_cen_test = np.concatenate((X_cen_test, X_dict[i]['test']), axis = 0)\n",
    "\n",
    "model_cen = LinearRegression().fit(X_cen_train, y_train)\n",
    "\n",
    "print('Centralized method with linear regression R2:',\n",
    "      round(r2_score(y_test, model_cen.predict(X_cen_test)),3))  \n",
    "print('Centralized method with linear regression MSE:',\n",
    "      round(mean_squared_error(y_test, model_cen.predict(X_cen_test)),3))\n",
    "\n",
    "res['Centralized(LR)']=[r2_score(y_test, model_cen.predict(X_cen_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464c6e2",
   "metadata": {},
   "source": [
    "## 2.3. Decentralized mehod\n",
    "\n",
    "In this subsection, a dictionary of prediction mehods is created for each product and the total accuracy of it is caculated then.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45b7b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decentralized method with linear regression R2: 0.517\n",
      "Decentralized method with linear regression MSE: 53537.475\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "skuModels = {}\n",
    "\n",
    "for i in skuSet:\n",
    " #one model for each item, fitted on training set\n",
    " model_i = OLS(y_dict[i]['train'], X_dict[i]['train'])\n",
    " skuModels[i] = model_i.fit()\n",
    "\n",
    " #compute and concatenate prediction of the model i on item i\n",
    " y_pred += list(skuModels[i].predict(X_dict[i]['test']))\n",
    "\n",
    "\n",
    "#computing overall performance metrics on y_pred and y_test:\n",
    "print('Decentralized method with linear regression R2:',round(r2_score(y_test, np.array(y_pred)),3))\n",
    "print('Decentralized method with linear regression MSE:', round(mean_squared_error(y_test, np.array(y_pred)),3))\n",
    "\n",
    "res['Decentralized(LR)']=[r2_score(y_test, np.array(y_pred))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c4b12f",
   "metadata": {},
   "source": [
    "# 3. Prediction with aggregated seasonality\n",
    "\n",
    "A common approach in retail is to covert the existing variable (or columns) into multiple variables, based on the avaialable product items. In this section, all the features, except for the seasonality, are cosidered at product item level inside the dataset. This method is called 'feature-fixed effect'. Note that this method may result in a better prediction for the centralized method, but the decentraized method already considers the dataset at the product item levels. As a result, the prediction accuracy of the decentralized method may not improve.\n",
    "\n",
    "## 3.1. Structuring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69ef7c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NOOR~1\\AppData\\Local\\Temp/ipykernel_14140/3443539507.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_seasonality[str(feature)+\"_fixed_effect_\"+str(i)] = sales_seasonality[feature]*sales_seasonality[\"sku_\"+str(i)]\n"
     ]
    }
   ],
   "source": [
    "sales_fe_sku = sales.copy()\n",
    "sales_fe_sku = pd.get_dummies(data=sales_fe_sku, columns=['sku'])\n",
    "sales_fe_sku[\"sku\"] = sales[\"sku\"] \n",
    "\n",
    "\n",
    "colnames_to_fix = [i for i in sales.columns if i not in [\"week\",\"weekly_sales\",\"sku\",\n",
    "                                                         'month_2', 'month_3', 'month_4', 'month_5', 'month_6',\n",
    "                                                         'month_7', 'month_8', 'month_9', 'month_10', 'month_11', \n",
    "                                                         'month_12']]\n",
    "\n",
    "sales_seasonality = sales_fe_sku.copy()\n",
    "\n",
    "for feature in colnames_to_fix:\n",
    "  for i in range(1,45):\n",
    "    sales_seasonality[str(feature)+\"_fixed_effect_\"+str(i)] = sales_seasonality[feature]*sales_seasonality[\"sku_\"+str(i)]\n",
    "\n",
    "skuSet = list(sales.sku.unique()) #the SKU numbers do not change\n",
    "skuData = {}\n",
    "colnames = [i for i in sales_seasonality.columns if i not in [\"week\",\"weekly_sales\",\"sku\"] and i not in colnames_to_fix]\n",
    "for i in skuSet:\n",
    "  df_i = sales_seasonality[sales_seasonality.sku == i]\n",
    "  skuData[i] = {'X': df_i[colnames].values,\n",
    "                'y': df_i.weekly_sales.values}\n",
    "    \n",
    "\n",
    "\n",
    "X_dict = {}\n",
    "y_dict = {}\n",
    "\n",
    "y_test = []\n",
    "y_train = []\n",
    "\n",
    "for i in skuSet:\n",
    "  \n",
    "  X_train_i,X_test_i = train_test_split(skuData[i][\"X\"], shuffle=False, train_size=0.7) #split for X\n",
    "  y_train_i,y_test_i = train_test_split(skuData[i][\"y\"], shuffle=False, train_size=0.7) #split for y \n",
    "\n",
    "  X_dict[i] = {'train': X_train_i, 'test': X_test_i} #filling dictionary\n",
    "  y_dict[i] = {'train': y_train_i, 'test': y_test_i}\n",
    "\n",
    "  y_test += list(y_test_i) \n",
    "  y_train += list(y_train_i) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff89fa",
   "metadata": {},
   "source": [
    "## 3.2. Centralized method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d939d9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonality aggregated (LR) R2: 0.616\n",
      "Seasonality aggregated (LR) MSE: 42516.024\n"
     ]
    }
   ],
   "source": [
    "X_cen_train = X_dict[skuSet[0]]['train'] #initialization with item 0\n",
    "X_cen_test = X_dict[skuSet[0]]['test']\n",
    "\n",
    "for i in skuSet[1:]: #Iteration over items\n",
    "    X_cen_train = np.concatenate((X_cen_train, X_dict[i]['train']), axis = 0) #Bringing together the training set\n",
    "    X_cen_test = np.concatenate((X_cen_test, X_dict[i]['test']), axis = 0)\n",
    "\n",
    "model_cen = LinearRegression(fit_intercept=True).fit(X_cen_train, y_train)\n",
    "print('Seasonality aggregated (LR) R2:', round(r2_score(y_test, model_cen.predict(X_cen_test)),3))  \n",
    "print('Seasonality aggregated (LR) MSE:', round(mean_squared_error(y_test, model_cen.predict(X_cen_test)),3))\n",
    "\n",
    "res['Centralized(SA-LR)']=[r2_score(y_test, model_cen.predict(X_cen_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1acbf3c",
   "metadata": {},
   "source": [
    "## 3.3. Decentralized method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "113a7640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS R2: 0.517\n",
      "OOS MSE: 53537.475\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "skuModelsElastic = {}\n",
    "\n",
    "for i in skuSet:\n",
    "    skuModels[i] = LinearRegression(fit_intercept=True).fit(X_dict[i][\"train\"],y_dict[i][\"train\"])\n",
    "    y_pred += list(skuModels[i].predict(X_dict[i]['test']))\n",
    "\n",
    "#computing overall performance metrics on y_pred and y_test:\n",
    "print('OOS R2:',round(r2_score(y_test, np.array(y_pred)),3))\n",
    "print('OOS MSE:', round(mean_squared_error(y_test, np.array(y_pred)),3))\n",
    "\n",
    "res['Decentralized(SA-LR)']=[r2_score(y_test, np.array(y_pred))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c51826",
   "metadata": {},
   "source": [
    "# 4. Regularization\n",
    "\n",
    "As you noticed, the dataset in the previous section includes so many variables. Therefore, some problems like overfitting or multicolinearity may occur, reducing the prediction accuracy or decrasing the reliablity on coefficients. In response, we deploy the Elasticnet method, which has the advantage of both Lasso and Ridge regressions. Note that a hypeparameter tuning algorithm is used to determine the best value of parameters of the Elasticnet method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71203250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3cd2a1",
   "metadata": {},
   "source": [
    "## 4.1. Centralized method\n",
    "\n",
    "In this subsection, we consider the seasonality aggregated approach (Section 3.2) for the centralized prediction method and use Elasticnet for prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Hyperparameter tuning\n",
    "BestR2 = -1\n",
    "BestPar = [-1,-1]\n",
    "\n",
    "idx1 = [0.1*i for i in range(1,11)] # Set of values for alpha\n",
    "idx2 = [0.1*i for i in range(11)]   # Set of values for l1_ratio\n",
    "\n",
    "#hyperparameter tuning for centralized\n",
    "for i in idx1:\n",
    "    for j in idx2:\n",
    "        model_cen = ElasticNet(alpha= i,l1_ratio=j)\n",
    "        model_cen.fit(X_cen_train, y_train)\n",
    "        R2 = r2_score(y_test, model_cen.predict(X_cen_test))\n",
    "        if R2>BestR2:\n",
    "            BestR2 = R2\n",
    "            BestPar[0] = i\n",
    "            BestPar[1] = j\n",
    "print('The best value of alpha:',BestPar[0])\n",
    "print('The best value of l1_ratio:',BestPar[1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5fc8aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonality aggregated (EN) R2: 0.632\n",
      "Seasonality aggregated (EN) MSE: 40766.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Sotwares\\Anaconda\\Installation\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10229889.879478272, tolerance: 21709.014304244654\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#model_cen = ElasticNet(alpha=BestPar[0],l1_ratio=BestPar[1])\n",
    "model_cen = ElasticNet(alpha=0.1,l1_ratio=1)\n",
    "model_cen.fit(X_cen_train, y_train)\n",
    "print('Seasonality aggregated (EN) R2:', round(r2_score(y_test, model_cen.predict(X_cen_test)),3))  \n",
    "print('Seasonality aggregated (EN) MSE:', round(mean_squared_error(y_test, model_cen.predict(X_cen_test)),3))\n",
    "\n",
    "res['Centralized(SA-EN)']=[r2_score(y_test, model_cen.predict(X_cen_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9bef25",
   "metadata": {},
   "source": [
    "## 4.2. Decentralized method\n",
    "\n",
    "In this subsection, we consider the seasonality aggregated approach (Section 3.3) for the centralized prediction method and use Elasticnet for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Hyperparameter Tuning\n",
    "BestR2 = -1\n",
    "BestPar = [-1,-1]\n",
    "\n",
    "idx1 = [0.1*i for i in range(1,11)] # Set of values for alpha\n",
    "idx2 = [0.1*i for i in range(11)]   # Set of values for l1_ratio\n",
    "\n",
    "for i in idx1:\n",
    "    for j in idx2:\n",
    "        y_pred = []\n",
    "        y_test = []\n",
    "        for k in skuSet:\n",
    "            elastic = ElasticNet(alpha= i,l1_ratio=j)\n",
    "            ModelsElastic = elastic.fit(X_dict[k][\"train\"],y_dict[k][\"train\"])\n",
    "            y_pred += list(ModelsElastic.predict(X_dict[k]['test']))\n",
    "            y_test += list(y_dict[k][\"test\"])\n",
    "        R2 = r2_score(np.array(y_test), np.array(y_pred))\n",
    "        if R2>BestR2:\n",
    "            BestR2 = R2\n",
    "            BestPar[0] = i\n",
    "            BestPar[1] = j\n",
    "            \n",
    "print('The best value of alpha:',BestPar[0])\n",
    "print('The best value of l1_ratio:',BestPar[1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4989769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonality aggregated (EN) R2: 0.595\n",
      "Seasonality aggregated (EN) MSE: 44882.604\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "skuModels = {}\n",
    "\n",
    "for i in skuSet:\n",
    "#    elastic = ElasticNet(alpha=BestPar[0],l1_ratio=BestPar[1])\n",
    "    elastic = ElasticNet(alpha=1,l1_ratio=0.9)\n",
    "    skuModels[i] = elastic.fit(X_dict[i][\"train\"],y_dict[i][\"train\"])\n",
    "    y_pred += list(skuModels[i].predict(X_dict[i]['test']))\n",
    "\n",
    "#computing overall performance metrics on y_pred and y_test:\n",
    "print('Seasonality aggregated (EN) R2:',round(r2_score(y_test, np.array(y_pred)),3))\n",
    "print('Seasonality aggregated (EN) MSE:', round(mean_squared_error(y_test, np.array(y_pred)),3))\n",
    "\n",
    "res['Decentralized(SA-EN)']=[r2_score(y_test, np.array(y_pred))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bebbeb",
   "metadata": {},
   "source": [
    "# 5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "582e6e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Centralized(LR)</th>\n",
       "      <th>Decentralized(LR)</th>\n",
       "      <th>Centralized(SA-LR)</th>\n",
       "      <th>Decentralized(SA-LR)</th>\n",
       "      <th>Centralized(SA-EN)</th>\n",
       "      <th>Decentralized(SA-EN)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.114249</td>\n",
       "      <td>0.516539</td>\n",
       "      <td>0.616066</td>\n",
       "      <td>0.516539</td>\n",
       "      <td>0.631869</td>\n",
       "      <td>0.594695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Centralized(LR)  Decentralized(LR)  Centralized(SA-LR)  \\\n",
       "R2         0.114249           0.516539            0.616066   \n",
       "\n",
       "    Decentralized(SA-LR)  Centralized(SA-EN)  Decentralized(SA-EN)  \n",
       "R2              0.516539            0.631869              0.594695  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e47e3",
   "metadata": {},
   "source": [
    "From the above chart, we notice that the most accurate approach is to make seasonality aggregated data and use Elasticnet ia a centralized approach. \n",
    "It is evident that the seasonality aggregated data plays an important role in the prediction accuracy of the centralized method. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
